# ğŸ¯ InterviewMaster AI

Assistant IA multi-agents pour la prÃ©paration d'entretiens d'embauche avec analyse de CV, recherche entreprise, gÃ©nÃ©ration de questions et simulation interactive.

## ğŸš€ FonctionnalitÃ©s

- **Analyse de CV**: Extraction automatique des compÃ©tences, expÃ©riences et points forts
- **Analyse de Poste**: ComprÃ©hension des exigences et responsabilitÃ©s
- **Recherche Entreprise**: Information en temps rÃ©el via recherche web
- **GÃ©nÃ©ration de Questions**: Questions personnalisÃ©es par catÃ©gorie
- **Simulation Interactive**: Mode interview avec feedback en temps rÃ©el
- **Monitoring Langfuse**: ObservabilitÃ© complÃ¨te du workflow
- **Persistance**: Sauvegarde de sessions avec SqliteSaver

## ğŸ—ï¸ Architecture
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Streamlit UI      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LangGraph Workflow â”‚
â”‚    (Supervisor)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”
    â”‚   Agents    â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ CV Analyzer â”‚
    â”‚ JD Analyzer â”‚
    â”‚ Researcher  â”‚
    â”‚ Q Generator â”‚
    â”‚ Coach       â”‚
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
           â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”
    â”‚   Tools     â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ Vector DB   â”‚
    â”‚ Web Search  â”‚
    â”‚ Doc Parser  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“‹ PrÃ©requis

- Python 3.10+
- Ollama (pour LLM local) OU clÃ©s API (OpenAI, Groq, etc.)
- Compte Tavily (API search gratuite)
- Compte Langfuse (monitoring)

## ğŸ”§ Installation

### 1. Cloner le repository
```bash
git clone https://github.com/votre-username/interview-master-ai.git
cd interview-master-ai
```

### 2. CrÃ©er un environnement virtuel
```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
# OU
venv\Scripts\activate  # Windows
```

### 3. Installer les dÃ©pendances
```bash
pip install -r requirements.txt
```

### 4. Configuration

Copier `.env.example` vers `.env` et remplir les variables:
```bash
cp .env.example .env
```

Ã‰diter `.env`:
```env
# LLM
OLLAMA_BASE_URL=http://localhost:11434
LLM_MODEL=llama3.1:8b

# Tavily
TAVILY_API_KEY=votre_clÃ©

# Langfuse
LANGFUSE_PUBLIC_KEY=votre_clÃ©
LANGFUSE_SECRET_KEY=votre_clÃ©
LANGFUSE_HOST=https://cloud.langfuse.com
```

### 5. Installer et lancer Ollama (si local)
```bash
# TÃ©lÃ©charger depuis https://ollama.com
ollama pull llama3.1:8b
ollama serve
```

## ğŸ® Utilisation

### Lancer l'application
```bash
streamlit run src/ui/streamlit_app.py
```

L'application sera accessible sur `http://localhost:8501`

### Workflow

1. **Upload** votre CV (PDF, DOCX, TXT)
2. **Fournir** la description de poste
3. **Entrer** le nom de l'entreprise
4. **Lancer l'analyse** et attendre la gÃ©nÃ©ration
5. **Valider** les questions proposÃ©es
6. **Consulter** les conseils personnalisÃ©s
7. **Simuler** l'entretien avec feedback temps rÃ©el
8. **TÃ©lÃ©charger** le rapport final

## ğŸ§ª Tests
```bash
# Tests unitaires
pytest tests/ -v

# Avec couverture
pytest tests/ --cov=src --cov-report=html
```

## ğŸ“Š Monitoring Langfuse

AccÃ©dez Ã  votre dashboard Langfuse pour voir:
- Traces des exÃ©cutions d'agents
- Temps de rÃ©ponse
- Tokens utilisÃ©s
- Erreurs et exceptions
- MÃ©triques de qualitÃ©

## ğŸš€ DÃ©ploiement

### Streamlit Cloud

1. Push le code sur GitHub
2. Connectez-vous sur [streamlit.io](https://streamlit.io)
3. DÃ©ployez depuis le repository
4. Ajoutez les secrets dans Settings

### Hugging Face Spaces
```bash
# CrÃ©er un Space sur HF
# Ajouter un fichier app.py Ã  la racine:
```

**app.py:**
```python
from src.ui.streamlit_app import main

if __name__ == "__main__":
    main()
```

### Docker (optionnel)

**Dockerfile:**
```dockerfile
FROM python:3.10-slim

WORKDIR /app

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY . .

EXPOSE 8501

CMD ["streamlit", "run", "src/ui/streamlit_app.py", "--server.port=8501", "--server.address=0.0.0.0"]
```
```bash
docker build -t interview-master-ai .
docker run -p 8501:8501 --env-file .env interview-master-ai
```

## ğŸ¤ Contribution

1. Fork le projet
2. CrÃ©er une branche (`git checkout -b feature/AmazingFeature`)
3. Commit (`git commit -m 'Add AmazingFeature'`)
4. Push (`git push origin feature/AmazingFeature`)
5. Ouvrir une Pull Request

## ğŸ“ License

MIT License

## ğŸ‘¥ Auteurs

Votre Ã‰quipe

## ğŸ™ Remerciements

- LangChain & LangGraph
- Anthropic Claude
- Streamlit
- Tavily
- Langfuse