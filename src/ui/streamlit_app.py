import streamlit as st
from pathlib import Path
import sys
import json
import os
from datetime import datetime

# Ajouter le r√©pertoire parent au path
sys.path.append(str(Path(__file__).parent.parent.parent))

from src.agents.cv_analyzer import CVAnalyzerAgent
from src.agents.jd_analyzer import JDAnalyzerAgent
from src.agents.company_researcher import CompanyResearcherAgent
from src.agents.question_generator import QuestionGeneratorAgent
from src.agents.interview_coach import InterviewCoachAgent
from src.agents.supervisor import InterviewPrepSupervisor, InterviewPrepState
from src.tools.document_parser import DocumentParser
from src.tools.web_search import WebSearchTool
from src.tools.vector_store import VectorStore
from src.utils.llm_config import LLMConfig
from src.utils.langfuse_config import LangfuseMonitoring
from langgraph.checkpoint.memory import MemorySaver

AGENT_VERSION = "2025-11-18-r3"

# Configuration de la page
st.set_page_config(
    page_title="InterviewMaster AI",
    page_icon="üéØ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Styles CSS personnalis√©s
st.markdown("""
<style>
    .main-header {
        font-size: 3rem;
        font-weight: bold;
        text-align: center;
        color: #1E88E5;
        margin-bottom: 2rem;
    }
    .step-header {
        background: linear-gradient(90deg, #1E88E5 0%, #42A5F5 100%);
        color: white;
        padding: 1rem;
        border-radius: 10px;
        margin: 1rem 0;
    }
    .success-box {
        background-color: #E8F5E9;
        border-left: 5px solid #4CAF50;
        padding: 1rem;
        border-radius: 5px;
        margin: 1rem 0;
    }
    .info-box {
        background-color: #E3F2FD;
        border-left: 5px solid #2196F3;
        padding: 1rem;
        border-radius: 5px;
        margin: 1rem 0;
    }
    .warning-box {
        background-color: #FFF3E0;
        border-left: 5px solid #FF9800;
        padding: 1rem;
        border-radius: 5px;
        margin: 1rem 0;
    }
</style>
""", unsafe_allow_html=True)

# Initialisation de la session
def init_session_state():
    """Initialise les variables de session"""
    if "workflow_state" not in st.session_state:
        st.session_state.workflow_state = None
    if "current_step" not in st.session_state:
        st.session_state.current_step = "upload"
    if "agents_initialized" not in st.session_state:
        st.session_state.agents_initialized = False
    if "agents_version" not in st.session_state:
        st.session_state.agents_version = None
    if "interview_started" not in st.session_state:
        st.session_state.interview_started = False
    if "current_question" not in st.session_state:
        st.session_state.current_question = 0

def reset_agents():
    """Force la r√©initialisation compl√®te des agents"""
    st.session_state.agents_initialized = False
    st.session_state.agents_version = None
    st.session_state.supervisor = None
    st.session_state.vector_store = None
    st.session_state.workflow_state = None
    st.session_state.current_step = "upload"
    st.session_state.interview_started = False
    st.session_state.current_question = 0
    st.rerun()

def initialize_agents():
    """Initialise tous les agents et outils"""
    if st.session_state.agents_initialized and st.session_state.get("agents_version") == AGENT_VERSION:
        return
    
    # Si on a des agents mais une ancienne version, forcer la r√©init
    if st.session_state.agents_initialized and st.session_state.get("agents_version") != AGENT_VERSION:
        st.session_state.agents_initialized = False
    
    with st.spinner("üöÄ Initialisation des agents IA..."):
        try:
            from dotenv import load_dotenv
            load_dotenv()

            if not os.getenv("OPENAI_API_KEY"):
                st.error("""
                ‚ùå **Cl√© OpenAI manquante**

                Configurez la variable d'environnement `OPENAI_API_KEY` (et
                √©ventuellement `OPENAI_API_BASE` si vous utilisez un proxy/Azure)
                puis rechargez la page.
                """)
                st.stop()
            
            # S'assurer que les mod√®les configur√©s sont compatibles OpenAI
            llm_model = os.getenv("LLM_MODEL", "gpt-4o-mini")
            if ":" in llm_model or "llama" in llm_model.lower():
                st.info("""
                ‚ÑπÔ∏è Le mod√®le configur√© (`LLM_MODEL`) n'est pas compatible avec OpenAI.
                Passage automatique √† `gpt-4o-mini`. Mettez √† jour votre `.env` pour
                √©viter ce message.
                """)
                llm_model = "gpt-4o-mini"
                os.environ["LLM_MODEL"] = llm_model

            embedding_model = os.getenv("EMBEDDING_MODEL", "text-embedding-3-small")
            if "nomic" in embedding_model.lower():
                st.info("""
                ‚ÑπÔ∏è Le mod√®le d'embeddings configur√© n'est pas compatible OpenAI.
                Passage automatique √† `text-embedding-3-small`. Mettez √† jour votre `.env`.
                """)
                embedding_model = "text-embedding-3-small"
                os.environ["EMBEDDING_MODEL"] = embedding_model
            
            # Monitoring Langfuse (obligatoire)
            langfuse_monitor = None
            langfuse_keys_present = os.getenv("LANGFUSE_PUBLIC_KEY") and os.getenv("LANGFUSE_SECRET_KEY")
            if not langfuse_keys_present:
                st.error("‚ùå Monitoring Langfuse requis. Veuillez d√©finir LANGFUSE_PUBLIC_KEY et LANGFUSE_SECRET_KEY dans votre environnement.")
                st.stop()
            try:
                langfuse_monitor = LangfuseMonitoring()
            except Exception as monitor_error:
                st.error(f"‚ùå Impossible d'initialiser Langfuse: {monitor_error}")
                st.stop()
            
            # Embeddings
            embeddings = LLMConfig.get_embeddings()
            
            # Outils
            web_search = WebSearchTool()
            vector_store = VectorStore(embeddings)
            
            # Cr√©er un LLM avec callback Langfuse pour chaque agent
            # Le callback doit √™tre attach√© directement au LLM pour capturer les outputs
            user_id = os.getenv("LANGFUSE_USER_ID", "anonymous_user")
            
            # Cr√©er les callbacks handlers
            cv_handler = langfuse_monitor.get_callback_handler("cv_analyzer", user_id)
            jd_handler = langfuse_monitor.get_callback_handler("jd_analyzer", user_id)
            company_handler = langfuse_monitor.get_callback_handler("company_researcher", user_id)
            question_handler = langfuse_monitor.get_callback_handler("question_generator", user_id)
            coach_handler = langfuse_monitor.get_callback_handler("interview_coach", user_id)
            
            # Cr√©er un LLM avec callback pour chaque agent
            llm_cv = LLMConfig.get_llm(callbacks=[cv_handler])
            llm_jd = LLMConfig.get_llm(callbacks=[jd_handler])
            llm_company = LLMConfig.get_llm(callbacks=[company_handler])
            llm_question = LLMConfig.get_llm(callbacks=[question_handler])
            llm_coach = LLMConfig.get_llm(callbacks=[coach_handler])
            
            agents = {
                "cv_analyzer": CVAnalyzerAgent(
                    llm_cv, 
                    callbacks=[cv_handler],
                    langfuse_monitor=langfuse_monitor
                ),
                "jd_analyzer": JDAnalyzerAgent(
                    llm_jd, 
                    callbacks=[jd_handler],
                    langfuse_monitor=langfuse_monitor
                ),
                "company_researcher": CompanyResearcherAgent(
                    llm_company, 
                    web_search, 
                    callbacks=[company_handler],
                    langfuse_monitor=langfuse_monitor
                ),
                "question_generator": QuestionGeneratorAgent(
                    llm_question, 
                    callbacks=[question_handler],
                    langfuse_monitor=langfuse_monitor
                ),
                "interview_coach": InterviewCoachAgent(
                    llm_coach, 
                    callbacks=[coach_handler],
                    langfuse_monitor=langfuse_monitor
                )
            }
            
            # Memory saver - utiliser MemorySaver au lieu de SqliteSaver pour √©viter le probl√®me du context manager
            # MemorySaver n'est pas un context manager et peut √™tre utilis√© directement
            memory = MemorySaver()
            
            # Supervisor - passer le checkpointer directement
            supervisor = InterviewPrepSupervisor(agents, vector_store, memory)
            
            # V√©rifier que la m√©thode get_graph existe
            if not hasattr(supervisor, 'get_graph'):
                st.error("‚ùå Erreur: La m√©thode get_graph n'est pas disponible. Veuillez red√©marrer Streamlit.")
                st.stop()
            
            # Stocker dans session state
            st.session_state.supervisor = supervisor
            st.session_state.vector_store = vector_store
            st.session_state.langfuse_monitor = langfuse_monitor
            st.session_state.agents_initialized = True
            st.session_state.agents_version = AGENT_VERSION
            
            st.success("‚úÖ Agents initialis√©s avec succ√®s!")
            
        except Exception as e:
            st.error(f"‚ùå Erreur lors de l'initialisation: {str(e)}")
            st.stop()

def upload_documents_section():
    """Section d'upload des documents"""
    st.markdown('<div class="step-header"><h2>üìÑ √âtape 1: Upload des Documents</h2></div>', 
                unsafe_allow_html=True)
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("### CV du Candidat")
        cv_file = st.file_uploader(
            "Uploadez votre CV",
            type=["pdf", "docx", "txt"],
            key="cv_upload"
        )
        
        if cv_file:
            st.success(f"‚úÖ CV upload√©: {cv_file.name}")
    
    with col2:
        st.markdown("### Description de Poste")
        jd_option = st.radio(
            "Comment fournir la description de poste?",
            ["üìù Saisie manuelle", "üìÑ Upload fichier"]
        )
        
        if jd_option == "üìÑ Upload fichier":
            jd_file = st.file_uploader(
                "Uploadez la description de poste",
                type=["pdf", "docx", "txt"],
                key="jd_upload"
            )
            jd_text = None
        else:
            jd_text = st.text_area(
                "Collez la description de poste",
                height=200,
                key="jd_text"
            )
            jd_file = None
    
    st.markdown("### üè¢ Informations sur l'Entreprise")
    company_name = st.text_input("Nom de l'entreprise", key="company_name")
    
    # Bouton de d√©marrage
    if st.button("üöÄ Lancer l'Analyse", type="primary", use_container_width=True):
        if not cv_file:
            st.error("‚ö†Ô∏è Veuillez uploader un CV")
            return
        
        if not jd_file and not jd_text:
            st.error("‚ö†Ô∏è Veuillez fournir une description de poste")
            return
        
        if not company_name:
            st.error("‚ö†Ô∏è Veuillez entrer le nom de l'entreprise")
            return
        
        # Parser les documents
        try:
            # Sauvegarder temporairement le CV
            cv_path = f"./data/cv/{cv_file.name}"
            Path("./data/cv").mkdir(parents=True, exist_ok=True)
            with open(cv_path, "wb") as f:
                f.write(cv_file.getbuffer())
            
            cv_content = DocumentParser.parse_document(cv_path)["content"]
            
            # Parser JD
            if jd_file:
                jd_path = f"./data/jd/{jd_file.name}"
                Path("./data/jd").mkdir(parents=True, exist_ok=True)
                with open(jd_path, "wb") as f:
                    f.write(jd_file.getbuffer())
                jd_content = DocumentParser.parse_document(jd_path)["content"]
            else:
                jd_content = jd_text
            
            # Initialiser l'√©tat du workflow
            initial_state = {
                "cv_text": cv_content,
                "cv_analysis": {},
                "jd_text": jd_content,
                "jd_analysis": {},
                "company_name": company_name,
                "company_info": {},
                "questions": [],
                "current_question_idx": 0,
                "user_answers": [],
                "feedback_history": [],
                "general_tips": {},
                "human_approval_needed": False,
                "human_feedback": "",
                "next_step": "",
                "error": ""
            }
            
            st.session_state.workflow_state = initial_state
            st.session_state.current_step = "analysis"
            st.rerun()
            
        except Exception as e:
            st.error(f"‚ùå Erreur lors du parsing: {str(e)}")

def analysis_section():
    """Section d'analyse et g√©n√©ration de questions"""
    st.markdown('<div class="step-header"><h2>üîç √âtape 2: Analyse et G√©n√©ration</h2></div>', 
                unsafe_allow_html=True)
    
    if st.session_state.workflow_state is None:
        st.warning("‚ö†Ô∏è Aucune donn√©e √† analyser")
        return
    
    # V√©rifier si l'analyse a d√©j√† √©t√© effectu√©e
    state = st.session_state.workflow_state
    analysis_done = (
        state.get("cv_analysis") and state["cv_analysis"] and
        state.get("jd_analysis") and state["jd_analysis"] and
        state.get("questions") and len(state.get("questions", [])) > 0
    )
    
    # Ex√©cuter le workflow seulement si l'analyse n'est pas encore faite
    if not analysis_done:
        # Ex√©cuter le workflow jusqu'au point de validation humaine
        with st.spinner("ü§ñ Les agents travaillent sur votre profil..."):
            try:
                supervisor = st.session_state.supervisor
                config = {"configurable": {"thread_id": "interview_prep_1"}}
                
                # Ex√©cuter le workflow
                # Avec MemorySaver, on peut utiliser le graph directement sans context manager
                graph = supervisor.get_graph()
                result = None
                last_state = None
                
                # Ex√©cuter le workflow et accumuler l'√©tat
                progress_bar = st.progress(0)
                status_text = st.empty()
                node_names = ["analyze_parallel", "research_company", "generate_questions", "human_review"]
                current_step = 0
                
                for state_update in graph.stream(st.session_state.workflow_state, config):
                    result = state_update
                    # state_update est un dict avec les noms des n≈ìuds comme cl√©s
                    # Chaque valeur est l'√©tat complet apr√®s l'ex√©cution de ce n≈ìud
                    if result:
                        # R√©cup√©rer l'√©tat du dernier n≈ìud ex√©cut√©
                        # Dans LangGraph, chaque it√©ration retourne un dict avec une cl√© (nom du n≈ìud)
                        # et la valeur est l'√©tat complet apr√®s ce n≈ìud
                        node_name = list(result.keys())[0] if result.keys() else None
                        node_state = list(result.values())[0] if result.values() else None
                        
                        if node_state:
                            last_state = node_state
                            
                            # Mettre √† jour la barre de progression
                            if node_name in node_names:
                                current_step = node_names.index(node_name) + 1
                                progress = current_step / len(node_names)
                                progress_bar.progress(progress)
                                
                                step_names = {
                                    "analyze_parallel": "üìÑ Analyse CV et JD en parall√®le...",
                                    "research_company": "üîç Recherche d'informations sur l'entreprise...",
                                    "generate_questions": "‚ùì G√©n√©ration des questions d'entretien...",
                                    "human_review": "‚úÖ Analyse termin√©e !"
                                }
                                status_text.text(step_names.get(node_name, f"Ex√©cution de {node_name}..."))
                            
                            # Monitoring Langfuse
                            langfuse_monitor = st.session_state.get("langfuse_monitor")
                            if langfuse_monitor:
                                try:
                                    langfuse_monitor.log_workflow_step(
                                        step_name=node_name,
                                        state=node_state,
                                        success=not bool(node_state.get("error"))
                                    )
                                except Exception:
                                    pass
                            
                            # Debug: afficher le n≈ìud ex√©cut√© et son √©tat (masqu√© par d√©faut)
                            # with st.expander(f"üîç Debug: Node {node_name}", expanded=False):
                            #     st.json({
                            #         "node": node_name,
                            #         "has_cv_analysis": bool(node_state.get("cv_analysis")),
                            #         "has_jd_analysis": bool(node_state.get("jd_analysis")),
                            #         "has_company_info": bool(node_state.get("company_info")),
                            #         "questions_count": len(node_state.get("questions", [])),
                            #         "error": node_state.get("error", "")
                            #     })
                            
                            # Arr√™ter au point de validation humaine
                            if node_state.get("next_step") == "awaiting_human_input":
                                break
            
                progress_bar.progress(1.0)
                status_text.text("‚úÖ Analyse termin√©e !")
                
                # Mettre √† jour l'√©tat avec le dernier √©tat r√©cup√©r√©
                if last_state:
                    # Fusionner avec l'√©tat initial pour pr√©server toutes les donn√©es
                    st.session_state.workflow_state = {**st.session_state.workflow_state, **last_state}
                elif result:
                    # Fallback: utiliser le dernier √©tat du dernier n≈ìud
                    node_state = list(result.values())[0] if result.values() else None
                    if node_state:
                        st.session_state.workflow_state = {**st.session_state.workflow_state, **node_state}
                
                # Debug: afficher les cl√©s de l'√©tat pour v√©rifier
                if st.session_state.workflow_state:
                    debug_info = {
                        "cv_analysis": bool(st.session_state.workflow_state.get("cv_analysis")),
                        "jd_analysis": bool(st.session_state.workflow_state.get("jd_analysis")),
                        "company_info": bool(st.session_state.workflow_state.get("company_info")),
                        "questions": len(st.session_state.workflow_state.get("questions", [])),
                        "error": st.session_state.workflow_state.get("error", "")
                    }
                    # Afficher en mode debug temporairement
                    with st.expander("üîç Debug Info", expanded=False):
                        st.json(debug_info)
                        st.json({k: type(v).__name__ for k, v in st.session_state.workflow_state.items()})
                        st.caption("Aper√ßu CV Analysis")
                        st.json(st.session_state.workflow_state.get("cv_analysis", {}))
                        st.caption("Aper√ßu JD Analysis")
                        st.json(st.session_state.workflow_state.get("jd_analysis", {}))
                        # Afficher l'erreur si pr√©sente
                        if st.session_state.workflow_state.get("error"):
                            st.error(f"Erreur dans le workflow: {st.session_state.workflow_state.get('error')}")
            
            except Exception as e:
                st.error(f"‚ùå Erreur: {str(e)}")
                import traceback
                st.error(f"Traceback: {traceback.format_exc()}")
                langfuse_monitor = st.session_state.get("langfuse_monitor")
                if langfuse_monitor:
                    try:
                        langfuse_monitor.log_workflow_step(
                            step_name="analysis_section_error",
                            state={"error": str(e)},
                            success=False
                        )
                    except Exception:
                        pass
                return
    else:
        # L'analyse est d√©j√† faite, utiliser l'√©tat existant
        state = st.session_state.workflow_state
    
    state = st.session_state.workflow_state
    
    # Afficher les r√©sultats
    st.success("‚úÖ Analyse termin√©e!")
    
    # Tabs pour organiser les r√©sultats
    tab1, tab2, tab3, tab4 = st.tabs(["üìä Analyse CV", "üìã Analyse Poste", "üè¢ Info Entreprise", "‚ùì Questions"])
    
    with tab1:
        if state.get("cv_analysis") and state["cv_analysis"]:
            st.markdown("### R√©sum√© de votre profil")
            cv_analysis = state["cv_analysis"]
            
            col1, col2 = st.columns(2)
            with col1:
                st.markdown("**üéØ Points Forts:**")
                strengths = cv_analysis.get("strengths", [])
                if strengths:
                    for strength in strengths:
                        st.markdown(f"- {strength}")
                else:
                    st.info("Aucun point fort identifi√©")
            
            with col2:
                st.markdown("**üìà Axes d'Am√©lioration:**")
                areas = cv_analysis.get("areas_for_improvement", [])
                if areas:
                    for area in areas:
                        st.markdown(f"- {area}")
                else:
                    st.info("Aucun axe d'am√©lioration identifi√©")
            
            st.markdown("**üíº Comp√©tences:**")
            skills = cv_analysis.get("skills", [])
            st.write(", ".join(skills) if skills else "Non sp√©cifi√©")
            
            summary = cv_analysis.get("summary", "")
            if summary:
                st.info(summary)
        else:
            st.warning("‚ö†Ô∏è L'analyse du CV n'est pas encore disponible. Le workflow est peut-√™tre en cours d'ex√©cution.")
            st.json(state.get("cv_analysis", {}))
    
    with tab2:
        if state.get("jd_analysis") and state["jd_analysis"]:
            jd_analysis = state["jd_analysis"]
            
            st.markdown(f"### {jd_analysis.get('job_title', 'Poste')}")
            st.markdown(f"**Niveau:** {jd_analysis.get('seniority_level', 'N/A')}")
            
            st.markdown("**üîß Comp√©tences Requises:**")
            skills = jd_analysis.get("required_skills", [])
            if skills:
                for skill in skills:
                    st.markdown(f"- {skill}")
            else:
                st.info("Aucune comp√©tence requise identifi√©e")
            
            st.markdown("**üìù Responsabilit√©s Principales:**")
            responsibilities = jd_analysis.get("key_responsibilities", [])
            if responsibilities:
                for resp in responsibilities[:5]:
                    st.markdown(f"- {resp}")
            else:
                st.info("Aucune responsabilit√© identifi√©e")
        else:
            st.warning("‚ö†Ô∏è L'analyse du poste n'est pas encore disponible.")
            st.json(state.get("jd_analysis", {}))
    
    with tab3:
        if state.get("company_info") and state["company_info"]:
            company_info = state["company_info"]
            
            st.markdown(f"### {company_info.get('company_name', state.get('company_name', 'Entreprise'))}")
            st.markdown(f"**Activit√©:** {company_info.get('main_activity', 'N/A')}")
            
            st.markdown("**üì∞ Actualit√©s R√©centes:**")
            news = company_info.get("recent_news", [])
            if news:
                for item in news:
                    st.markdown(f"- {item}")
            else:
                st.info("Aucune actualit√© r√©cente disponible")
            
            st.markdown("**üí° Valeurs:**")
            values = company_info.get("values", [])
            st.write(", ".join(values) if values else "Non disponible")
        else:
            st.warning("‚ö†Ô∏è Les informations sur l'entreprise ne sont pas encore disponibles.")
            st.json(state.get("company_info", {}))
    
    with tab4:
        if state.get("questions"):
            st.markdown("### Questions d'Entretien G√©n√©r√©es")
            
            questions = state["questions"]
            
            # Grouper par cat√©gorie
            categories = {}
            for q in questions:
                cat = q.get("category", "Autre")
                if cat not in categories:
                    categories[cat] = []
                categories[cat].append(q)
            
            for category, questions_list in categories.items():
                with st.expander(f"üìå {category} ({len(questions_list)} questions)"):
                    for idx, q in enumerate(questions_list, 1):
                        st.markdown(f"**Q{idx}:** {q['question']}")
                        st.caption(f"üéØ Objectif: {q.get('objective', 'N/A')}")
                        
                        with st.container():
                            st.markdown("üí° **Conseils:**")
                            for tip in q.get("tips", []):
                                st.markdown(f"  - {tip}")
                        st.markdown("---")
    
    # Validation humaine
    st.markdown('<div class="info-box">', unsafe_allow_html=True)
    st.markdown("### üë§ Validation Humaine")
    st.write("Les questions vous conviennent-elles? Vous pouvez:")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if st.button("‚úÖ Approuver et Continuer", type="primary", use_container_width=True):
            st.session_state.workflow_state["human_feedback"] = "approved"
            st.session_state.workflow_state["human_approval_needed"] = False
            st.session_state.current_step = "tips"
            st.rerun()
    
    with col2:
        if st.button("üîÑ R√©g√©n√©rer Questions", use_container_width=True):
            st.session_state.workflow_state["human_feedback"] = "regenerate"
            st.rerun()
    
    with col3:
        if st.button("üéØ Passer √† la Simulation", use_container_width=True):
            st.session_state.workflow_state["human_feedback"] = "interview"
            st.session_state.workflow_state["human_approval_needed"] = False
            st.session_state.current_step = "interview"
            st.rerun()
    
    st.markdown('</div>', unsafe_allow_html=True)

def tips_section():
    """Section de conseils de pr√©paration"""
    st.markdown('<div class="step-header"><h2>üí° √âtape 3: Conseils de Pr√©paration</h2></div>', 
                unsafe_allow_html=True)
    
    state = st.session_state.workflow_state
    
    # G√©n√©rer les conseils si pas encore fait
    if not state.get("general_tips"):
        with st.spinner("üìù G√©n√©ration de conseils personnalis√©s..."):
            supervisor = st.session_state.supervisor
            config = {
                "configurable": {"thread_id": "interview_prep_1"},
                "recursion_limit": 50,
            }
            
            # Continuer le workflow
            # Avec MemorySaver, on peut utiliser le graph directement sans context manager
            graph = supervisor.get_graph()
            for result in graph.stream(state, config):
                st.session_state.workflow_state = list(result.values())[0]
                if st.session_state.workflow_state.get("general_tips"):
                    break
            
            state = st.session_state.workflow_state
    
    tips = state.get("general_tips", {})
    
    if tips:
        # Checklist de pr√©paration
        st.markdown("### ‚úÖ Checklist de Pr√©paration")
        for item in tips.get("preparation_checklist", []):
            st.checkbox(item, key=f"checklist_{hash(item)}")
        
        # Points forts √† mettre en avant
        with st.expander("üí™ Points Forts √† Mettre en Avant", expanded=True):
            for strength in tips.get("strengths_to_highlight", []):
                st.success(f"‚úì {strength}")
        
        # Pr√©occupations potentielles
        with st.expander("‚ö†Ô∏è Points d'Attention"):
            concerns = tips.get("potential_concerns", [])
            for concern in concerns:
                if isinstance(concern, dict):
                    st.warning(f"**Pr√©occupation:** {concern.get('concern', '')}")
                    how_to = (
                        concern.get("how_to_address")
                        or concern.get("solution")
                        or concern.get("action")
                        or concern.get("advice")
                        or ""
                    )
                    if how_to:
                        st.info(f"**Comment l'adresser:** {how_to}")
                else:
                    st.warning(concern)
        
        # Conseils pratiques
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("### üëî Code Vestimentaire")
            st.info(tips.get("dress_code", "Tenue professionnelle adapt√©e au secteur"))
            
            st.markdown("### üö´ Erreurs √† √âviter")
            mistakes = tips.get("common_mistakes") or tips.get("mistakes") or []
            if mistakes:
                for mistake in mistakes:
                    st.markdown(f"- {mistake}")
            else:
                st.caption("Pas d'erreurs sp√©cifiques remont√©es.")
        
        with col2:
            st.markdown("### ü§ù Langage Corporel")
            st.info(tips.get("body_language", "Maintenez un contact visuel et une posture confiante"))
    
    # Bouton pour d√©marrer la simulation
    if st.button("üé≠ D√©marrer la Simulation d'Entretien", type="primary", use_container_width=True):
        st.session_state.current_step = "interview"
        st.session_state.interview_started = True
        st.rerun()

def interview_simulation_section():
    """Section de simulation d'entretien"""
    st.markdown('<div class="step-header"><h2>üé≠ √âtape 4: Simulation d\'Entretien</h2></div>',
                unsafe_allow_html=True)
    
    state = st.session_state.workflow_state
    questions = state.get("questions", [])
    current_idx = st.session_state.current_question
    
    if current_idx >= len(questions):
        # Entretien termin√©
        st.success("üéâ Simulation d'entretien termin√©e!")
        st.session_state.current_step = "report"
        st.rerun()
        return
    
    # Barre de progression
    progress = current_idx / len(questions)
    st.progress(progress, text=f"Question {current_idx + 1} sur {len(questions)}")
    
    # Question courante
    current_question = questions[current_idx]
    
    st.markdown(f"### Question {current_idx + 1}")
    st.markdown(f"**Cat√©gorie:** {current_question.get('category', 'N/A')}")
    st.markdown(f"**Difficult√©:** {current_question.get('difficulty', 'medium').upper()}")
    
    st.markdown('<div class="info-box">', unsafe_allow_html=True)
    st.markdown(f"## {current_question['question']}")
    st.markdown('</div>', unsafe_allow_html=True)
    
    # Zone de r√©ponse
    answer = st.text_area(
        "Votre r√©ponse:",
        height=200,
        key=f"answer_{current_idx}",
        placeholder="Prenez votre temps pour structurer une r√©ponse claire et pertinente..."
    )
    
    # Conseils (optionnels)
    with st.expander("üí° Voir les conseils"):
        st.markdown("**Objectif de la question:**")
        st.write(current_question.get('objective', 'N/A'))
        
        st.markdown("**Conseils pour r√©pondre:**")
        for tip in current_question.get('tips', []):
            st.markdown(f"- {tip}")
    
    # Boutons d'action
    col1, col2, col3 = st.columns([2, 2, 1])
    
    with col1:
        if st.button("üìù Soumettre et Obtenir Feedback", type="primary", use_container_width=True):
            if not answer or len(answer.strip()) < 10:
                st.error("‚ö†Ô∏è Veuillez fournir une r√©ponse plus d√©taill√©e")
            else:
                # Sauvegarder la r√©ponse
                if "user_answers" not in state:
                    state["user_answers"] = []
                
                state["user_answers"].append({
                    "question_idx": current_idx,
                    "question": current_question["question"],
                    "answer": answer,
                    "timestamp": datetime.now().isoformat()
                })
                
                # Obtenir le feedback
                with st.spinner("ü§ñ Analyse de votre r√©ponse..."):
                    coach = st.session_state.supervisor.agents["interview_coach"]
                    context = {
                        "cv": state["cv_analysis"],
                        "jd": state["jd_analysis"]
                    }
                    
                    feedback_result = coach.evaluate_answer(
                        current_question["question"],
                        answer,
                        context
                    )
                    
                    if feedback_result["success"]:
                        feedback = feedback_result["feedback"]
                        
                        # Afficher le feedback
                        st.markdown("---")
                        st.markdown("### üìä Feedback sur Votre R√©ponse")
                        
                        # Score
                        score = feedback.get("score", 0)
                        st.metric("Score", f"{score}/10")
                        
                        # Points positifs
                        st.markdown("#### ‚úÖ Points Positifs")
                        for point in feedback.get("positive_points", []):
                            st.success(point)
                        
                        # Points √† am√©liorer
                        st.markdown("#### üìà Points √† Am√©liorer")
                        for point in feedback.get("improvement_areas", []):
                            st.warning(point)
                        
                        # R√©ponse am√©lior√©e
                        with st.expander("üí° Suggestion de R√©ponse Am√©lior√©e"):
                            st.write(feedback.get("improved_answer", ""))
                        
                        # Conseils sp√©cifiques
                        st.markdown("#### üéØ Conseils Sp√©cifiques")
                        for tip in feedback.get("specific_tips", []):
                            st.info(tip)
                        
                        # Encouragement
                        st.markdown('<div class="success-box">', unsafe_allow_html=True)
                        st.markdown(f"**üí™ {feedback.get('encouragement', 'Continuez comme √ßa!')}**")
                        st.markdown('</div>', unsafe_allow_html=True)
                        
                        # Sauvegarder le feedback
                        if "feedback_history" not in state:
                            state["feedback_history"] = []
                        
                        state["feedback_history"].append({
                            "question_idx": current_idx,
                            "feedback": feedback
                        })
                        
                        st.session_state.workflow_state = state
    
    with col2:
        if st.button("‚è≠Ô∏è Question Suivante", use_container_width=True):
            st.session_state.current_question += 1
            st.rerun()
    
    with col3:
        if st.button("‚è∏Ô∏è Pause", use_container_width=True):
            st.info("Simulation en pause. Cliquez sur 'Continuer' quand vous √™tes pr√™t.")

def report_section():
    """Section de rapport final"""
    st.markdown('<div class="step-header"><h2>üìä Rapport Final de Pr√©paration</h2></div>', 
                unsafe_allow_html=True)
    
    state = st.session_state.workflow_state
    
    st.balloons()
    st.success("üéâ F√©licitations! Vous avez termin√© votre pr√©paration d'entretien!")
    
    # Statistiques globales
    st.markdown("### üìà Vos Statistiques")
    
    col1, col2, col3, col4 = st.columns(4)
    
    feedback_history = state.get("feedback_history", [])
    
    if feedback_history:
        avg_score = sum(f["feedback"].get("score", 0) for f in feedback_history) / len(feedback_history)
        
        with col1:
            st.metric("Score Moyen", f"{avg_score:.1f}/10")
        
        with col2:
            st.metric("Questions R√©pondues", len(feedback_history))
        
        with col3:
            good_scores = sum(1 for f in feedback_history if f["feedback"].get("score", 0) >= 7)
            st.metric("Bonnes R√©ponses", f"{good_scores}/{len(feedback_history)}")
        
        with col4:
            completion = (len(feedback_history) / len(state.get("questions", []))) * 100
            st.metric("Compl√©tion", f"{completion:.0f}%")
    
    # D√©tails par question
    st.markdown("### üìù D√©tail de Vos R√©ponses")
    
    for idx, feedback_item in enumerate(feedback_history, 1):
        with st.expander(f"Question {idx} - Score: {feedback_item['feedback'].get('score', 0)}/10"):
            user_answer = next((a for a in state.get("user_answers", []) 
                              if a["question_idx"] == feedback_item["question_idx"]), None)
            
            if user_answer:
                st.markdown(f"**Question:** {user_answer['question']}")
                st.markdown(f"**Votre r√©ponse:** {user_answer['answer']}")
                
                feedback = feedback_item["feedback"]
                
                col1, col2 = st.columns(2)
                with col1:
                    st.markdown("**Points Positifs:**")
                    for point in feedback.get("positive_points", []):
                        st.markdown(f"- ‚úÖ {point}")
                
                with col2:
                    st.markdown("**Points √† Am√©liorer:**")
                    for point in feedback.get("improvement_areas", []):
                        st.markdown(f"- üìà {point}")
    
    # Recommandations finales
    st.markdown("### üéØ Recommandations Finales")
    
    if feedback_history:
        # Analyser les forces et faiblesses
        all_improvement_areas = []
        all_positive_points = []
        
        for f in feedback_history:
            all_improvement_areas.extend(f["feedback"].get("improvement_areas", []))
            all_positive_points.extend(f["feedback"].get("positive_points", []))
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("#### üí™ Vos Forces")
            unique_strengths = list(set(all_positive_points))[:5]
            for strength in unique_strengths:
                st.success(f"‚úì {strength}")
        
        with col2:
            st.markdown("#### üìö Axes de Travail")
            unique_improvements = list(set(all_improvement_areas))[:5]
            for improvement in unique_improvements:
                st.warning(f"‚Üí {improvement}")
    
    # Export du rapport
    st.markdown("### üíæ Export du Rapport")
    
    if st.button("üìÑ T√©l√©charger le Rapport (JSON)", use_container_width=True):
        report_data = {
            "date": datetime.now().isoformat(),
            "company": state.get("company_name", "N/A"),
            "position": state.get("jd_analysis", {}).get("job_title", "N/A"),
            "statistics": {
                "average_score": avg_score if feedback_history else 0,
                "questions_answered": len(feedback_history),
                "total_questions": len(state.get("questions", []))
            },
            "answers": state.get("user_answers", []),
            "feedback": feedback_history,
            "tips": state.get("general_tips", {})
        }
        
        json_str = json.dumps(report_data, indent=2, ensure_ascii=False)
        st.download_button(
            label="‚¨áÔ∏è T√©l√©charger",
            data=json_str,
            file_name=f"interview_prep_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
            mime="application/json"
        )
    
    # Bouton pour recommencer
    if st.button("üîÑ Nouvelle Pr√©paration", type="primary", use_container_width=True):
        # Reset session state
        for key in list(st.session_state.keys()):
            del st.session_state[key]
        st.rerun()

def main():
    """Fonction principale de l'application"""
    
    # Header
    st.markdown('<h1 class="main-header">üéØ InterviewMaster AI</h1>', unsafe_allow_html=True)
    st.markdown('<p style="text-align: center; font-size: 1.2rem; color: #666;">Votre coach IA pour r√©ussir vos entretiens d\'embauche</p>', unsafe_allow_html=True)
    
    # Initialiser la session
    init_session_state()
    
    # Apr√®s rechargement complet, garantir que current_step existe toujours
    if "current_step" not in st.session_state or st.session_state.current_step is None:
        st.session_state.current_step = "upload"
    
    # Sidebar
    with st.sidebar:
        if st.button("‚ôªÔ∏è R√©initialiser les agents IA", use_container_width=True):
            reset_agents()
        
        st.markdown("## üéØ Navigation")
        
        # Indicateur de progression
        steps = ["upload", "analysis", "tips", "interview", "report"]
        current_step_idx = steps.index(st.session_state.current_step) if st.session_state.current_step in steps else 0
        
        for idx, step in enumerate(steps):
            step_names = {
                "upload": "1Ô∏è‚É£ Upload Documents",
                "analysis": "2Ô∏è‚É£ Analyse & Questions",
                "tips": "3Ô∏è‚É£ Conseils",
                "interview": "4Ô∏è‚É£ Simulation",
                "report": "5Ô∏è‚É£ Rapport"
            }
            
            if idx < current_step_idx:
                st.success(step_names[step] + " ‚úÖ")
            elif idx == current_step_idx:
                st.info(step_names[step] + " üîÑ")
            else:
                st.text(step_names[step])
        
        st.markdown("---")
        
        # Informations
        st.markdown("## ‚ÑπÔ∏è √Ä Propos")
        st.markdown("""
        **InterviewMaster AI** utilise:
        - ü§ñ Agents IA multi-sp√©cialis√©s
        - üîç Recherche web en temps r√©el
        - üìä RAG pour analyse contextuelle
        - üíæ Persistance des sessions
        - üìà Monitoring Langfuse
        """)
        
        st.markdown("---")
        
        # Aide
        with st.expander("‚ùì Aide"):
            st.markdown("""
            **Comment utiliser l'application:**
            
            1. **Upload**: Fournissez votre CV et la description de poste
            2. **Analyse**: Laissez les agents analyser et g√©n√©rer des questions
            3. **Validation**: Approuvez ou r√©g√©n√©rez les questions
            4. **Conseils**: Consultez les recommandations personnalis√©es
            5. **Simulation**: R√©pondez aux questions et recevez du feedback
            6. **Rapport**: Consultez vos statistiques et t√©l√©chargez le rapport
            """)
        
        # Status des agents
        if st.session_state.agents_initialized:
            st.success("üü¢ Agents IA: Actifs")
        else:
            st.warning("üü° Agents IA: Non initialis√©s")
    
    # Initialiser les agents
    initialize_agents()
    
    # Router vers la bonne section
    if st.session_state.current_step == "upload":
        upload_documents_section()
    elif st.session_state.current_step == "analysis":
        analysis_section()
    elif st.session_state.current_step == "tips":
        tips_section()
    elif st.session_state.current_step == "interview":
        interview_simulation_section()
    elif st.session_state.current_step == "report":
        report_section()

if __name__ == "__main__":
    main()